ğŸ¤– Serverless AI Voice Assistant

A complete serverless AI voice assistant that processes voice commands, converts them to text, generates AI responses, and converts responses back to speech. Built with a React + TypeScript frontend, Flask backend, and deployed on AWS Lambda using Terraform.

ğŸŒŸ Features

ğŸ¤ Voice Processing: Record and process voice commands

ğŸ¤– AI Integration: OpenAI-powered intelligent responses

ğŸŒ¤ï¸ Weather Information: Real-time weather data integration

ğŸ”Š Text-to-Speech: Convert AI responses to natural-sounding speech

â˜ï¸ Serverless Architecture: Fully serverless deployment on AWS

ğŸš€ Automated Deployment: Single-command deployment pipeline

ğŸŒ Web Interface: Modern React-based user interface

```
serverless-AI-voice-assistant/
â”œâ”€â”€ ai_project/ # Frontend React/Vite TypeScript application
â”œâ”€â”€ flask_file/ # Backend Python/Flask application
â”‚ â”œâ”€â”€ ffmpeg/ # FFmpeg binaries for audio processing
â”‚ â”œâ”€â”€ uploads/ # Voice samples and uploads directory
â”‚ â”œâ”€â”€ Assistant2.py # Main Lambda function handler
â”‚ â”œâ”€â”€ buildlambda.ps1 # Lambda package builder script
â”‚ â”œâ”€â”€ requirements.txt # Python dependencies
â”‚ â””â”€â”€ response.wav # Sample response file
â”œâ”€â”€ terraform/ # Infrastructure as Code
â”‚ â”œâ”€â”€ main.tf # Main Terraform configuration
â”‚ â””â”€â”€ variables.tf # Terraform variables
â”œâ”€â”€ deploy.ps1 # Main deployment script
â””â”€â”€ README.md # This file
```


âœ… Prerequisites

AWS account with CLI configured

Node.js (v16+)

Python (3.9+)

Terraform (optional â€” deploy script can handle it)

OpenWeather API Key (get one from OpenWeatherMap)

ğŸš€ Installation & Deployment
Method 1 â€” One-Click Deployment (recommended)
# Set your OpenWeather API key as environment variable
$env:WEATHER_API_KEY = "your_openweather_api_key_here"

# Run the deployment script
.\deploy.ps1

Method 2 â€” Step-by-step Deployment

Clone and prepare:

git clone <your-repo-url>
cd serverless-AI-voice-assistant


Set environment variable (PowerShell):

$env:WEATHER_API_KEY = "your_api_key_here"


Run the deployment script:

.\deploy.ps1

ğŸ”§ What the Deployment Script Does

The deploy.ps1 script automates the deployment:

âœ… Prerequisites check (AWS, Node, Python)

âœ… AWS authentication check

ğŸ—ï¸ Backend build (packages Python + dependencies)

â˜ï¸ Infrastructure deployment (Terraform)

âš›ï¸ Frontend build (React with configured API endpoint)

ğŸŒ Frontend deployment (Netlify or manual instructions)

ğŸ—ï¸ Architecture Details
AWS Infrastructure (Terraform)

The Terraform code in /terraform creates:

S3 Bucket (lambda_bucket) â€” stores Lambda deployment package (private).

IAM Role & Policy (lambda_role) â€” execution role with CloudWatch & S3 access.

Lambda Function (voice_assistant) â€” Python 3.9 runtime, 1024MB memory, 60s timeout. Handler: Assistant2.lambda_handler.

API Gateway (voice_assistant_api) â€” HTTP API with CORS + proxy integration to Lambda.

Permissions â€” API Gateway permission to invoke Lambda; S3 object for Lambda code.

Note: I fixed the numbering and made it sequential.

ğŸ Backend (Python / Flask)

Located in /flask_file:

Assistant2.py: Main Lambda handler with endpoints:

/ â€” Health check

/process â€” Process voice commands

/test-voice â€” Test voice functionality

Audio processing uses FFmpeg (put binaries in /flask_file/ffmpeg/). Supports multiple audio formats and handles speech-to-text / text-to-speech.

âš›ï¸ Frontend (React / TypeScript)

Located in /ai_project:

Built with Vite + React + TypeScript

Voice recording interface, real-time response display, and audio playback controls

Uses environment variables to configure the backend API URL

ğŸ”§ Manual Deployment Steps

Run these if you prefer full manual control.

Build Lambda package

cd flask_file
.\buildlambda.ps1
cd ..


Deploy infrastructure

cd terraform
terraform init
terraform apply -var="weather_api_key=YOUR_API_KEY"
cd ..


Build Frontend

cd ai_project
npm install
npm run build
cd ..


Deploy to Netlify

Use Netlify CLI:

netlify deploy --prod --dir=dist


OR upload the dist folder via the Netlify dashboard.

ğŸ“‹ Environment Variables
Variable	Description	Required
WEATHER_API_KEY	OpenWeatherMap API key	Yes
VITE_API_BASE_URL	Backend API URL (frontend)	Auto-generated / set in env
ğŸ§ª Testing Your Deployment
# Test health check
curl <your-api-gateway-url>

# Example response
# {"message":"Voice Assistant Backend is running!"}

ğŸ” Troubleshooting
Common issues & fixes

AWS Authentication Failed

aws configure
# Enter your AWS Access Key, Secret Key, and region


FFmpeg Issues

Ensure FFmpeg binaries exist in /flask_file/ffmpeg/ and have execution permission.

Lambda Timeout

Audio processing may exceed default timeout. Set timeout to 60s or increase if needed.

CORS Errors

Confirm API Gateway CORS configuration and check VITE_API_BASE_URL in the frontend.

Logs & Monitoring

Lambda logs: CloudWatch Logs

API Gateway logs: enable access logging if necessary

Frontend logs: browser dev tools

ğŸ“Š Cost Estimation

This deployment uses AWS Free Tierâ€“eligible services:

AWS Lambda: 1M free requests / month

API Gateway: 1M free API calls / month

S3: first 5GB free

CloudWatch: basic monitoring free

Estimated monthly cost for moderate usage: <$5 (estimate; actual varies by usage).

ğŸ”„ Updating the Application

Update backend code

cd flask_file
# make changes to Assistant2.py
.\buildlambda.ps1
cd ../terraform
terraform apply


Update frontend

cd ai_project
# make changes
npm run build
# redeploy to Netlify

ğŸ—‘ï¸ Cleanup

To remove all deployed resources:

cd terraform
terraform destroy

ğŸ¤ Contributing

Fork the repo

Create a feature branch

Make changes & test thoroughly

Submit a pull request

ğŸ“„ License

MIT License â€” see LICENSE file for details.

ğŸ™ Acknowledgments

OpenAI for AI capabilities

AWS for serverless infrastructure

OpenWeatherMap for weather data

FFmpeg for audio processing

ğŸ“ Support

If you need help:

Check the troubleshooting section

Open a GitHub issue

Review AWS documentation for specific services

Built with â¤ï¸ using serverless technology â€” Happy coding! ğŸš€
